{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch3d.structures.meshes.Meshes at 0x7f46ac1ffd00>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch3d.renderer import look_at_view_transform\n",
    "from pytorch3d.io import load_obj\n",
    "import torch\n",
    "from pytorch3d.renderer import FoVPerspectiveCameras\n",
    "import pytorch3d\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vertices, faces, _ = load_obj(\"data/cow.obj\")\n",
    "vertices = vertices.unsqueeze(0)\n",
    "faces = faces.verts_idx.unsqueeze(0)\n",
    "\n",
    "texture_rgb = torch.ones_like(vertices) # N X 3\n",
    "texture_rgb = texture_rgb * torch.tensor([0.7, 0.7, 1])\n",
    "textures = pytorch3d.renderer.TexturesVertex(texture_rgb) #\n",
    "\n",
    "meshes = pytorch3d.structures.Meshes(\n",
    "    verts=vertices, # batched tensor or a list of tensors\n",
    "    faces=faces,\n",
    "    textures=textures,\n",
    ")\n",
    "meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Collect garbage\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def generate_spiral_points(n_points=100):\n",
    "    \"\"\"\n",
    "    Generate points on a sphere in a continuous spiral pattern from top to bottom.\n",
    "    \n",
    "    Args:\n",
    "        n_points: Number of points to generate\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (elevations, azimuths) in degrees\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate points from top to bottom (90° to -90°)\n",
    "    elevations = torch.linspace(85, -85, n_points)\n",
    "\n",
    "    azimuth_step = 360.0 / (n_points / 4)  # base step\n",
    "    azimuths = (torch.arange(n_points) * azimuth_step) % 360\n",
    "    \n",
    "    return elevations, azimuths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cameras = 50\n",
    "elevations, azimuths = generate_spiral_points(num_cameras)\n",
    "# Get camera positions using look_at_view_transform\n",
    "R, T = look_at_view_transform(\n",
    "    dist=3,\n",
    "    elev=elevations,\n",
    "    azim=azimuths,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Create a batch of cameras\n",
    "cameras = FoVPerspectiveCameras(device=device, R=R, T=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the number of cameras for each direction\n",
    "num_azimuth = 18  # horizontal rotation (every 10 degrees)\n",
    "num_elevation = 18  # vertical rotation (every 10 degrees)\n",
    "num_cameras = num_azimuth * num_elevation\n",
    "\n",
    "# Create evenly spaced angles for both azimuth and elevation\n",
    "azim = torch.linspace(0, 360, num_azimuth)\n",
    "elev = torch.linspace(-80, 80, num_elevation)  # Avoiding exact poles (-90/90) to prevent numerical issues\n",
    "\n",
    "# Create a grid of all angle combinations\n",
    "azim_grid, elev_grid = torch.meshgrid(azim, elev, indexing='ij')\n",
    "azim_all = azim_grid.flatten()\n",
    "elev_all = elev_grid.flatten()\n",
    "\n",
    "# Define the distance of the cameras from the object\n",
    "R, T = look_at_view_transform(\n",
    "    dist=3,\n",
    "    elev=elev_all,\n",
    "    azim=azim_all, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Create a batch of cameras\n",
    "cameras = FoVPerspectiveCameras(device=device, R=R, T=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pytorch3d.vis.plotly_vis import plot_scene\n",
    "plot_scene({\n",
    "    \"360-degree Renders\": {\n",
    "        \"Mesh\": meshes,\n",
    "        \"Cameras\": cameras,\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.renderer import (\n",
    "    RasterizationSettings,\n",
    "    MeshRenderer,\n",
    "    MeshRasterizer,\n",
    "    SoftPhongShader,\n",
    "    PointLights,\n",
    ")\n",
    "\n",
    "from starter.utils import get_mesh_renderer\n",
    "\n",
    "# Move the mesh to the device\n",
    "meshes = meshes.to(device)\n",
    "\n",
    "# Create a renderer\n",
    "raster_settings = RasterizationSettings(\n",
    "    image_size=512,\n",
    "    blur_radius=0.0,\n",
    "    faces_per_pixel=1,\n",
    ")\n",
    "\n",
    "lights = PointLights(device=device, location=[[0.0, 0.0, -3.0]])\n",
    "\n",
    "renderer = get_mesh_renderer(lights=lights, image_size=512, device=device)\n",
    "\n",
    "# Render the images\n",
    "images = renderer(meshes.extend(num_cameras), cameras=cameras, lights=lights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "images = images.cpu().numpy()[:, :, :, :3] # [1, H, W, rgb]\n",
    "images = [(image*255).astype(np.uint8) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "duration = 0.00005  # Convert FPS (frames per second) to duration (ms per frame)\n",
    "imageio.mimsave('play/loop-circle-cameras-new.gif', images, duration=duration, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cameras, lights, meshes, renderer, R, T\n",
    "del images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
