{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from starter.utils import unproject_depth_image\n",
    "from starter.render_generic import load_rgbd_data\n",
    "from starter.utils import get_device\n",
    "import torch, numpy as np\n",
    "import pytorch3d\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rgb1', 'mask1', 'depth1', 'rgb2', 'mask2', 'depth2', 'cameras1', 'cameras2'])\n"
     ]
    }
   ],
   "source": [
    "data = load_rgbd_data()\n",
    "print(data.keys())\n",
    "rgbs = [data['rgb1'], data['rgb2']]\n",
    "rgbs = [torch.from_numpy(rgb).to(device) for rgb in rgbs]\n",
    "masks = [data['mask1'], data['mask2']]\n",
    "masks = [torch.from_numpy(mask).to(device) for mask in masks]\n",
    "depth = [data['depth1'], data['depth2']]\n",
    "depth = [torch.from_numpy(depth).to(device) for depth in depth]\n",
    "cameras = [data['cameras1'], data['cameras2']]\n",
    "cameras = [camera.to(device) for camera in cameras]\n",
    "# print(cameras[0]) # PerspectiveCameras()\n",
    "# print(rgbs[0].shape) # (800, 800, 3)\n",
    "# print(masks[0].shape) # (800, 800)\n",
    "# print(depth[0].shape) # (800, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = 12\n",
    "def wrapper_unproject_depth_image(depth, camera, mask, image, repeat=1):\n",
    "    points, rgb = unproject_depth_image(depth=depth, camera=camera, mask=mask, image=image)\n",
    "    points = points.unsqueeze(0).repeat(repeat, 1, 1)\n",
    "    rgb = rgb[...,:3].unsqueeze(0).repeat(repeat, 1, 1)\n",
    "    return points, rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingyunxu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pytorch3d.renderer import look_at_view_transform\n",
    "from starter.utils import get_points_renderer\n",
    "\n",
    "def render_pc_from_points(points, features):\n",
    "    point_cloud = pytorch3d.structures.Pointclouds(points=points, features=features)\n",
    "    points_renderer = get_points_renderer(\n",
    "        image_size=256, \n",
    "        radius=0.01,\n",
    "    )\n",
    "    azims = torch.linspace(0, 360, num_views)\n",
    "    R, T = look_at_view_transform(6.0, 0, azim=azims)\n",
    "    pc_cameras = pytorch3d.renderer.PerspectiveCameras(\n",
    "        R=R, \n",
    "        T=T, \n",
    "        device=device\n",
    "    )\n",
    "    rend = points_renderer(point_cloud, cameras=pc_cameras)\n",
    "    # print(rend.shape) # [B, S, S, 3]\n",
    "    image_list = rend[..., :3].cpu().numpy()\n",
    "    images = (image_list*255).astype(np.uint8)\n",
    "    # print(image_list.shape)\n",
    "    return np.flip(images, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "points_list = []\n",
    "rgb_list = []\n",
    "for i in range(len(cameras)):\n",
    "    points, rgb = wrapper_unproject_depth_image(depth=depth[i], camera=cameras[i], mask=masks[i], image=rgbs[i], \n",
    "                                                repeat=num_views) \n",
    "    points_list.append(points)\n",
    "    rgb_list.append(rgb)\n",
    "    images = render_pc_from_points(points, rgb)\n",
    "    duration = 0.00005  # Convert FPS (frames per second) to duration (ms per frame)\n",
    "    imageio.mimsave(f'play/5-rendering-pc/plants-view-{i}.gif', images, duration=duration, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_union = torch.cat(points_list, dim=1)\n",
    "rgb_union = torch.cat(rgb_list, dim=1)\n",
    "images = render_pc_from_points(points_union, rgb_union)\n",
    "duration = 0.00005  # Convert FPS (frames per second) to duration (ms per frame)\n",
    "imageio.mimsave(f'play/5-rendering-pc/plants-union.gif', images, duration=duration, loop=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
